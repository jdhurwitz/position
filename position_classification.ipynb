{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.fftpack\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import scipy.fftpack\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "position_labels={\n",
    "    'layingdown':0,\n",
    "    'sitting':1,\n",
    "    'standing':2,\n",
    "    'walking':3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(path, timesteps):\n",
    "    X = []\n",
    "    y = []\n",
    "    positions = ['layingdown','sitting','standing','walking']\n",
    "    print(path)\n",
    "    for ip, p in enumerate(positions):\n",
    "        data = []\n",
    "        with open(path+p+'/1_android.sensor.accelerometer.data.csv') as f:\n",
    "            # ts = find_sampling_freq(path, p)\n",
    "            # if ts == 0:\n",
    "            ts = timesteps\n",
    "            print('\\tsampling freq = %i'% ts)\n",
    "            row = []\n",
    "            for i, line in enumerate(f):\n",
    "                row.append([float(x) for x in line.split(',')[1:4]])\n",
    "                if len(row) == ts:\n",
    "                    data.append(np.stack(row))\n",
    "                    row = []\n",
    "        data = np.stack(data)\n",
    "        print(\"\\t%s : %i examples loaded\" % (p, data.shape[0]))\n",
    "        X.append(data)\n",
    "        y.append(np.zeros(data.shape[0])+ip)\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    y = np.concatenate(y)\n",
    "    # print(X.shape, y.shape)\n",
    "    return (X, y)\n",
    "\n",
    "def pull_raw_data(path, position):\n",
    "    #sampling freq = 250Hz\n",
    "\n",
    "    num_lines = subprocess.call(['wc', '-l', path])\n",
    "    num_secs = num_lines/(250*60)\n",
    "    X = []\n",
    "    with open(path) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            X.append([float(x) for x in line.split(',')[1:4]])\n",
    "            \n",
    "    y = np.zeros(len(X))+position_labels[position]\n",
    "    return np.asarray(X), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    # Plot the frequency response.\n",
    "    \"\"\"\n",
    "    w, h = freqz(b, a, worN=8000)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(0.5*fs*w/np.pi, np.abs(h), 'b')\n",
    "    plt.plot(cutoff, 0.5*np.sqrt(2), 'ko')\n",
    "    plt.axvline(cutoff, color='k')\n",
    "    plt.xlim(0, 0.5*fs)\n",
    "    plt.title(\"Lowpass Filter Frequency Response\")\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.grid()\n",
    "    \"\"\"\n",
    "    return y\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def split_accel_axes(data):\n",
    "    #assumes 2 axis \n",
    "    samples, axes = data.shape\n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "    z = data[:,2]\n",
    "    return x,y,z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-10e1208bcfc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m X_walk, y_walk = pull_raw_data('data/train/walking/1_android.sensor.accelerometer.data.csv',\n\u001b[0;32m----> 2\u001b[0;31m                                 position='walking')\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m X_stand, y_stand = pull_raw_data('data/train/standing/1_android.sensor.accelerometer.data.csv',\n\u001b[1;32m      5\u001b[0m                                 position='standing')\n",
      "\u001b[0;32m<ipython-input-254-8d8b94bd8d10>\u001b[0m in \u001b[0;36mpull_raw_data\u001b[0;34m(path, position)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_walk, y_walk = pull_raw_data('data/train/walking/1_android.sensor.accelerometer.data.csv',\n",
    "                                position='walking')\n",
    "\n",
    "X_stand, y_stand = pull_raw_data('data/train/standing/1_android.sensor.accelerometer.data.csv',\n",
    "                                position='standing')\n",
    "\n",
    "X_sit, y_sit = pull_raw_data('data/train/sitting/1_android.sensor.accelerometer.data.csv',\n",
    "                                position='sitting')\n",
    "\n",
    "X_lay, y_lay = pull_raw_data('data/train/layingdown/1_android.sensor.accelerometer.data.csv',\n",
    "                                position='layingdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Walking \n",
    "We expect a periodic signal that's sinusoidal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_axis(data, title, x_name, y_name, range):\n",
    "    f = plt.figure(1)\n",
    "    plt.plot(np.arange(len(data)), data)\n",
    "    plt.title(title+' whole signal')\n",
    "    plt.ylabel(y_name)\n",
    "    plt.xlabel(x_name)\n",
    "    f.show()\n",
    "\n",
    "\n",
    "    g = plt.figure(2)\n",
    "    plt.plot(np.arange(range), data[5000:range+5000]) \n",
    "    plt.title(title+' zoomed in signal')\n",
    "    plt.ylabel(y_name)\n",
    "    plt.xlabel(x_name)\n",
    "\n",
    "    #plt.xlim((5000, 5000+range))\n",
    "    g.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-axis\n",
    "While the whole signal does not appear to exhibit any periodicity, it's clear from the zoomed in plot that the signal is periodic. It's extremely noisy though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split by axis into x,y,z\n",
    "x_sp, y_sp, z_sp = split_accel_axes(X_walk)\n",
    "\n",
    "#plotting x\n",
    "plot_axis(x_sp, title='X-axis', x_name='time', y_name='amplitude', range=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y-axis\n",
    "Visualizing the y-axis signals. The first plot shows that there are extremely high amplitude peaks, which will correspond to high frequency components. These are likely outliers and will need to be removed. The zoomed in plot only shows the first 1500 steps and does not include any of the outlier points. However, it's still a periodic signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting y\n",
    "plot_axis(y_sp, title='Y-axis', x_name='time', y_name='amplitude', range=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-axis\n",
    "Z-axis visualization. This axis also exhibits periodicity but the amplitude of the signals is less. The plot on the bottom shows a range of 5000, because it's not immediately clear from the first plot that this signal is characteristically sinusoidal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting z\n",
    "plot_axis(z_sp, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways from Walking Visualizations\n",
    "All three accelerometer axes for walking are sinusoidal as expected. Therefore, it would make sense to clean the data and then perform a frequency domain transformation. Data cleaning will involve removing outliers and performing curve smoothing via Savitzky-Golay. Removing sharp edges is a form of low pass filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Laying Down\n",
    "We expect this to just be essentially a flatline with some noise for the occasional movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-axis\n",
    "As expected, laying down has no periodicity because there is supposed to be no movement. The points of movement are likely a combination of noise and occsional arm movement; it's impossible to be fully still, even when sleeping! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split by axis into x,y,z\n",
    "x_ld, y_ld, z_ld = split_accel_axes(X_lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(x_ld, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(y_ld, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(z_ld, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Standing Up\n",
    "We expected this to look essentially the same as laying down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split by axis into x,y,z\n",
    "x_su, y_su, z_su = split_accel_axes(X_stand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-axis\n",
    "It appears that the wearer moved several times with the device. These are not periodic signals even though they resemble a distorted and shifted square wave. It's likely that the wearer moved into one position and then moved back into the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(x_su, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(y_su, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(z_su, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Sitting\n",
    "Also expecting to see a flatline with some peaks from occasional movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split by axis into x,y,z\n",
    "x_si, y_si, z_si = split_accel_axes(X_sit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(x_si, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(y_si, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis(z_si, title='X-axis', x_name='time', y_name='amplitude', range=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Interpretation \n",
    "As expected, walking is periodic whereas the other signals are not. There are occasional peaks in the other signals from when the wearer moved slightly. Extremely high frequency peaks can be removed but sustained movement cannot be \"filtered\" out without distorting the signal too much and the integrity of the data. <br> <br>\n",
    "For the walking data, we will apply Savitzky-Golay curve smoothing to remove some of the rough edges. The other signals will be low pass filtered. A frequency domain transform such as an FFT really only makes sense for walking, where there is some degree of periodicity. For the other activities that are essentially all DC-components, it's useless. Therefore, the input to a model would ideally be some combination of a frequency domain representation along with either the signals themselves or other data. There's no way that a learning algorithm would be able to tell the difference between sitting, standing, and lying down from a frequency domain representation because in the ideal case there is no movement. FFT or similar type of transform would be sufficient if the task was to classify different movement patters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "def reject_xyz_outliers(x,y,z):\n",
    "    return reject_outliers(x), reject_outliers(y), reject_outliers(z)\n",
    "\n",
    "#Basic outlier reject and mean shift\n",
    "def perform_preprocessing(x, y, z):\n",
    "    x = reject_outliers(x)\n",
    "    y = reject_outliers(y)\n",
    "    z = reject_outliers(z)\n",
    "    \n",
    "    #zero mean \n",
    "    x = x - np.mean(x)\n",
    "    y = y - np.mean(y)\n",
    "    z = z - np.mean(z)\n",
    "    \n",
    "    return x,y,z\n",
    "\n",
    "#Savitzky-Golay curve smoothing\n",
    "def smooth_curve(x,y,z, window_size=51, polynomial=3):\n",
    "    x_hat = scipy.signal.savgol_filter(x, window_size, polynomial)\n",
    "    y_hat = scipy.signal.savgol_filter(y, window_size, polynomial)\n",
    "    z_hat = scipy.signal.savgol_filter(z, window_size, polynomial)\n",
    "    \n",
    "    return x_hat, y_hat, z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suffix p to denote post processing\n",
    "#walking\n",
    "x_wp, y_wp, z_wp = reject_xyz_outliers(x_sp, y_sp, z_sp)\n",
    "\n",
    "#laying down \n",
    "x_ldp, y_ldp, z_sdp = reject_xyz_outliers(x_ld, y_ld, z_ld)\n",
    "\n",
    "#sitting\n",
    "x_sitp, y_sitp, z_sitp = reject_xyz_outliers(x_si, y_si, z_si)\n",
    "\n",
    "#standing\n",
    "x_stp, y_stp, z_stp = reject_xyz_outliers(x_su, y_su, z_su)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curve Smoothing \n",
    "Shown below is the \"walking\" curve after outliers are rejected, zero-mean, and curve smoothing is applied. The same technique is applied to other signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell out the args that were passed to the Matlab function\n",
    "x_sp_hat = scipy.signal.savgol_filter(x_sp, 51, 3)\n",
    "plot_axis(x_sitp, title='X-axis', x_name='time', y_name='amplitude', range=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suffix p to denote post processing\n",
    "#walking\n",
    "x_wp, y_wp, z_wp = smooth_curve(x_wp, y_wp, z_wp)\n",
    "\n",
    "#laying down \n",
    "x_ldp, y_ldp, z_sdp = smooth_curve(x_ldp, y_ldp, z_sdp)\n",
    "\n",
    "#sitting\n",
    "x_sitp, y_sitp, z_sitp = smooth_curve(x_sitp, y_sitp, z_sitp)\n",
    "\n",
    "#standing\n",
    "x_stp, y_stp, z_stp = smooth_curve(x_stp, y_stp, z_stp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.subplot(2, 1,1)\n",
    "order = 5\n",
    "xwp_filtered = butter_bandpass_filter(x_wp, 0.1, 25, 250, order)\n",
    "ywp_filtered = butter_bandpass_filter(y_wp, 0.1, 25, 250, order)\n",
    "zwp_filtered = butter_bandpass_filter(z_wp, 0.1, 25, 250, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqx = np.fft.rfft(xwp_filtered)\n",
    "freqx = np.abs(freqx)\n",
    "max_x = argrelextrema(freqx, np.greater)\n",
    "#print(max_x)\n",
    "\n",
    "#plt.plot(freqx[:250])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqy = np.fft.rfft(ywp_filtered)\n",
    "freqy = np.abs(freqy)\n",
    "max_y = argrelextrema(freqy, np.greater)\n",
    "#print(max_y)\n",
    "#plt.plot( freqy[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqz = np.fft.rfft(zwp_filtered)\n",
    "freqz = np.abs(freqz)\n",
    "max_z = argrelextrema(freqz, np.greater)\n",
    "#print(max_z)\n",
    "#plt.plot(freqz[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset('data/train/', timesteps=750)\n",
    "X_train_time, y_train_time = create_dataset('data/train/', timesteps=250)\n",
    "\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_train_time = np.nan_to_num(X_train_time)\n",
    "\n",
    "X_test, y_test = create_dataset('data/test/', timesteps=750)\n",
    "X_test_time, y_test_time = create_dataset('data/test/', timesteps=250)\n",
    "\n",
    "X_test = np.nan_to_num(X_test)\n",
    "X_test_time = np.nan_to_num(X_test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding for y (keras)\n",
    "def create_one_hot(vec):\n",
    "    vec_new = []\n",
    "    for val in vec:\n",
    "        if val == 0:\n",
    "            vec_new.append([1,0,0,0])\n",
    "        elif val == 1:\n",
    "            vec_new.append([0,1,0,0])\n",
    "        elif val == 2: \n",
    "            vec_new.append([0,0,1,0])\n",
    "        elif val == 3:\n",
    "            vec_new.append([0,0,0,1])\n",
    "\n",
    "    return vec_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X.shape)\n",
    "#print(y.shape)\n",
    "\n",
    "\n",
    "y_train_oh = np.asarray(create_one_hot(y_train))\n",
    "y_test_oh = np.asarray(create_one_hot(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For each chunk, go through and perform preprocessing then take FFT\n",
    "def get_ffts(data):\n",
    "    x_ffts = []\n",
    "    y_ffts = []\n",
    "    z_ffts = []\n",
    "    for sample in data:\n",
    "        x, y, z = split_accel_axes(sample)\n",
    "        x, y, z = reject_xyz_outliers(x, y, z)\n",
    "        x, y, z = smooth_curve(x, y, z)\n",
    "        x_filtered = butter_bandpass_filter(x, 0.1, 25, 250, )\n",
    "        y_filtered = butter_bandpass_filter(y, 0.1, 25, 250, 5)\n",
    "        z_filtered = butter_bandpass_filter(z, 0.1, 25, 250, 5)\n",
    "\n",
    "        #take FFTs\n",
    "        freqx = np.fft.rfft(x_filtered)\n",
    "        freqx = np.abs(freqx)\n",
    "        max_x = argrelextrema(freqx, np.greater)\n",
    "\n",
    "        freqy = np.fft.rfft(y_filtered)\n",
    "        freqy = np.abs(freqy)\n",
    "        max_y = argrelextrema(freqy, np.greater)\n",
    "\n",
    "        freqz = np.fft.rfft(z_filtered)\n",
    "        freqz = np.abs(freqz)\n",
    "        max_z = argrelextrema(freqz, np.greater)\n",
    "\n",
    "\n",
    "        #only keep data up to the sampling frequency \n",
    "        x_ffts.append(freqx[0:250].reshape(250, 1))\n",
    "        y_ffts.append(freqy[0:250].reshape(250, 1))\n",
    "        z_ffts.append(freqz[0:250].reshape(250, 1))\n",
    "\n",
    "    x_ffts = np.asarray(x_ffts)\n",
    "    y_ffts = np.asarray(y_ffts)\n",
    "    z_ffts = np.asarray(z_ffts)\n",
    "    \n",
    "    return x_ffts, y_ffts, z_ffts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_ffts, y_ffts, z_ffts = get_ffts(X)\n",
    "x_ffts_test, y_ffts_test, z_ffts_test = get_ffts(X_test)\n",
    "x_ffts_train, y_ffts_train, z_ffts_train = get_ffts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_ffts_train.shape)\n",
    "print(y_ffts_train.shape) \n",
    "print(z_ffts_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_stats(y_test, y_pred, y_pred_prob):\n",
    "    import itertools\n",
    "    from sklearn import linear_model\n",
    "    from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "    def plot_confusion_matrix(cm, classes,\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1,2,3])\n",
    "    plot_confusion_matrix(cnf_matrix, ['laying down', 'sitting', 'standing', 'walking'], title='Confusion Matrix')\n",
    "\n",
    " #   fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,0], pos_label=0)\n",
    "#    plt.plot(fpr, tpr, label='AUC =  %.3f' % roc_auc_score(y_test, y_pred_prob[:,0]))\n",
    "  #  plt.title('ROC Curve')\n",
    "   # plt.ylabel('True Positive Rate')\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    print('F1-score = %0.3f, Accuracy = %.3f' % (f1_score(y_test, y_pred, average='macro'), accuracy_score(y_test, y_pred), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual-Domain RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, LSTM, Merge\n",
    "import keras.optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Two branch network architecture <br>\n",
    "branch1: raw signal input <br>\n",
    "branch2: 3 FFTs fed into individual LSTMs for spectrum recognition  <br>\n",
    "\n",
    "The idea here is that if there is periodic information, branch 2 will be able to pick it up and activate output neurons corresponding to the walking class. This is an extendable model since it would allow for more types of classification, such as running, sprinting, or really anything with periodicity. If there is no frequency information, such as in the case of lying down, sitting, or standing, the left branch will be able to determine the action by the waveforms alone. With more sensors, more branches could be added and output layers essentially act as the final decision maker or selector of which branch to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dropout=0.5 #0.4 -> 0.58 accuracy\n",
    "recurrent_dropout = 0.2\n",
    "\n",
    "branch1 = Sequential()\n",
    "branch1.add(LSTM(100, input_shape=(750, 3), dropout=dropout, recurrent_dropout=dropout))\n",
    "branch1.add(Dense(4))\n",
    "\n",
    "\n",
    "#branch 2 requires sub-branches 2_x, 2_y, 2_z\n",
    "branch2_x = Sequential()\n",
    "branch2_x.add(LSTM(100, input_shape=(250, 1), dropout=dropout, recurrent_dropout=dropout))\n",
    "branch2_x.add(Dense(4))\n",
    "\n",
    "branch2_y = Sequential()\n",
    "branch2_y.add(LSTM(100, input_shape=(250, 1), dropout=dropout, recurrent_dropout=dropout))\n",
    "branch2_x.add(Dense(4))\n",
    "\n",
    "branch2_z = Sequential()\n",
    "branch2_z.add(LSTM(100, input_shape=(250, 1), dropout=dropout, recurrent_dropout=dropout))\n",
    "branch2_z.add(Dense(4))\n",
    "\n",
    "branch2 = Sequential()\n",
    "branch2.add(Merge([branch2_x, branch2_y, branch2_z], mode='concat'))\n",
    "branch2.add(Dense(4))\n",
    "\n",
    "#Merge the two branches\n",
    "model = Sequential()\n",
    "model.add(Merge([branch1, branch2], mode='concat'))\n",
    "model.add(Dense(4, activation='softmax')) #final output layer\n",
    "\n",
    "#model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit([X_train, x_ffts_train, y_ffts_train, z_ffts_train], y_train_oh, epochs = 50, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate([X_test, x_ffts_test, y_ffts_test, z_ffts_test], y_test_oh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict([X_test, x_ffts_test, y_ffts_test, z_ffts_test]) \n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "show_stats(y_test, y_classes, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
